{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ecd06a",
   "metadata": {},
   "source": [
    "æœ¬æ–‡å‚è€ƒèµ„æ–™æ˜¯[Hugging Faceä¸»é¡µ](https://huggingface.co/)Resourcesä¸‹çš„è¯¾ç¨‹,èŠ‚é€‰éƒ¨åˆ†å†…å®¹å¹¶æ³¨é‡Šï¼ˆåŠ ç²—æ–œä½“ï¼‰ï¼Œä¹ŸåŠ äº†Trainerå’Œargsçš„ä¸»è¦å‚æ•°ä»‹ç»ã€‚æ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å»æŸ¥çœ‹[åŸæ–‡](https://huggingface.co/course/chapter1)ã€‚\n",
    "****\n",
    "æœ¬ç« èŠ‚ä¸»è¦å†…å®¹åŒ…å«ä¸¤éƒ¨åˆ†å†…å®¹ï¼š\n",
    "- pipelineå·¥å…·æ¼”ç¤ºNLPä»»åŠ¡å¤„ç†\n",
    "- æ„å»ºTrainerå¾®è°ƒæ¨¡å‹<br>\n",
    "\n",
    "ç›®å½•\n",
    "- [1.  ç®€ä»‹](#1--ç®€ä»‹)\n",
    "  - [Transformersçš„å†å²](#transformersçš„å†å²)\n",
    "  - [Architectureså’Œcheckpoints](#architectureså’Œcheckpoints)\n",
    "  - [The Inference API](#the-inference-api)\n",
    "- [2. ç”¨pipelineå¤„ç†NLPé—®é¢˜](#2-ç”¨pipelineå¤„ç†nlpé—®é¢˜)\n",
    "- [3. Behind the pipeline](#3-behind-the-pipeline)\n",
    "  - [tokenizeré¢„å¤„ç†](#tokenizeré¢„å¤„ç†)\n",
    "  - [é€‰æ‹©æ¨¡å‹](#é€‰æ‹©æ¨¡å‹)\n",
    "  - [Model heads](#model-heads)\n",
    "  - [Post-processingåå¤„ç†](#post-processingåå¤„ç†)\n",
    "- [4. æ„å»ºTrainer APIå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹](#4-æ„å»ºtrainer-apiå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹)\n",
    "  - [ä»Hubä¸Šä¸‹è½½dataset](#ä»hubä¸Šä¸‹è½½dataset)\n",
    "  - [æ•°æ®é›†é¢„å¤„ç†](#æ•°æ®é›†é¢„å¤„ç†)\n",
    "  - [ä½¿ç”¨ Trainer API åœ¨ PyTorch ä¸­è¿›è¡Œå¾®è°ƒ](#ä½¿ç”¨-trainer-api-åœ¨-pytorch-ä¸­è¿›è¡Œå¾®è°ƒ)\n",
    "    - [è®­ç»ƒ](#è®­ç»ƒ)\n",
    "    - [è¯„ä¼°å‡½æ•°](#è¯„ä¼°å‡½æ•°)\n",
    "- [5. è¡¥å……éƒ¨åˆ†](#5-è¡¥å……éƒ¨åˆ†)\n",
    "  - [ä¸ºä»€ä¹ˆæ•™ç¨‹ç¬¬å››ç« éƒ½æ˜¯ç”¨Traineræ¥å¾®è°ƒæ¨¡å‹ï¼Ÿ](#ä¸ºä»€ä¹ˆæ•™ç¨‹ç¬¬å››ç« éƒ½æ˜¯ç”¨traineræ¥å¾®è°ƒæ¨¡å‹)\n",
    "  - [TrainingArgumentsä¸»è¦å‚æ•°](#trainingargumentsä¸»è¦å‚æ•°)\n",
    "  - [ä¸åŒçš„æ¨¡å‹åŠ è½½æ–¹å¼](#ä¸åŒçš„æ¨¡å‹åŠ è½½æ–¹å¼)\n",
    "  - [Dynamic paddingâ€”â€”åŠ¨æ€å¡«å……æŠ€æœ¯](#dynamic-paddingåŠ¨æ€å¡«å……æŠ€æœ¯)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0c69d",
   "metadata": {},
   "source": [
    "## 1.  ç®€ä»‹\n",
    "æœ¬ç« èŠ‚å°†ä½¿ç”¨ [Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„åº“](https://github.com/huggingface)â€”â€”ğŸ¤— Transformersæ¥è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†å·¥ä½œ(NLP)ã€‚\n",
    "### Transformersçš„å†å²\n",
    "ä»¥ä¸‹æ˜¯ Transformer æ¨¡å‹ï¼ˆç®€çŸ­ï¼‰å†å²ä¸­çš„ä¸€äº›å‚è€ƒç‚¹ï¼š\n",
    "![transformers_chrono](https://img-blog.csdnimg.cn/3ba51fe4f21d4d528ca7b0f2fd78aee4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA56We5rSb5Y2O,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)\n",
    "[Transformer æ¶æ„](https://arxiv.org/abs/1706.03762)äº 2017 å¹´ 6 æœˆæ¨å‡ºã€‚åŸå§‹ç ”ç©¶çš„é‡ç‚¹æ˜¯ç¿»è¯‘ä»»åŠ¡ã€‚éšåæ¨å‡ºäº†å‡ ä¸ªæœ‰å½±å“åŠ›çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "\n",
    "- 2018 å¹´ 6 æœˆï¼š[GPT](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)ï¼Œç¬¬ä¸€ä¸ªé¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ï¼Œç”¨äºå„ç§ NLP ä»»åŠ¡çš„å¾®è°ƒå¹¶è·å¾—æœ€å…ˆè¿›çš„ç»“æœ\n",
    "- 2018 å¹´ 10 æœˆï¼š[BERT](https://arxiv.org/abs/1810.04805)ï¼Œå¦ä¸€ä¸ªå¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨ç”Ÿæˆæ›´å¥½çš„å¥å­æ‘˜è¦ï¼ˆä¸‹ä¸€ç« å°†è¯¦ç»†ä»‹ç»ï¼ï¼‰\n",
    "- 2019 å¹´ 2 æœˆï¼š[GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)ï¼ŒGPT çš„æ”¹è¿›ï¼ˆå’Œæ›´å¤§ï¼‰ç‰ˆæœ¬ï¼Œç”±äºé“å¾·é—®é¢˜æœªç«‹å³å…¬å¼€å‘å¸ƒ\n",
    "- 2019 å¹´ 10 æœˆï¼š[DistilBERT](https://arxiv.org/abs/1910.01108)ï¼ŒBERT çš„è’¸é¦ç‰ˆæœ¬ï¼Œé€Ÿåº¦æé«˜ 60%ï¼Œå†…å­˜å‡è½» 40%ï¼Œä½†ä»ä¿ç•™ BERT 97% çš„æ€§èƒ½\n",
    "- 2019 å¹´ 10 æœˆï¼š[BART](https://arxiv.org/abs/1910.13461) å’Œ [T5](https://arxiv.org/abs/1910.10683)ï¼Œä¸¤ä¸ªä½¿ç”¨ä¸åŸå§‹ Transformer æ¨¡å‹ç›¸åŒæ¶æ„çš„å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç¬¬ä¸€ä¸ªè¿™æ ·åšï¼‰\n",
    "- 2020 å¹´ 5 æœˆï¼Œ[GPT-3](https://arxiv.org/abs/2005.14165)ï¼ŒGPT-2 çš„æ›´å¤§ç‰ˆæœ¬ï¼Œæ— éœ€å¾®è°ƒå³å¯åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆç§°ä¸ºé›¶æ ·æœ¬å­¦ä¹ zero-shot learningï¼‰\n",
    "\n",
    "è¿™ä¸ªåˆ—è¡¨å¹¶ä¸å…¨ï¼Œåªæ˜¯ä¸ºäº†çªå‡ºä¸€äº›ä¸åŒç±»å‹çš„ Transformer æ¨¡å‹ã€‚å¤§ä½“ä¸Šï¼Œå®ƒä»¬å¯ä»¥åˆ†ä¸ºä¸‰ç±»ï¼š\n",
    "\n",
    "- GPTç±»ï¼ˆåªä½¿ç”¨transformer-decoderéƒ¨åˆ†ï¼Œè‡ªå›å½’ Transformer æ¨¡å‹ï¼‰\n",
    "- BERTç±»ï¼ˆåªä½¿ç”¨transformer-encoderéƒ¨åˆ†ï¼Œè‡ªç¼–ç  Transformer æ¨¡å‹ï¼‰\n",
    "- BART/T5 ç±»ï¼ˆTransformer-encoder-decoderæ¨¡å‹ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991f9d9",
   "metadata": {},
   "source": [
    "### Architectureså’Œcheckpoints\n",
    "å¯¹Transformeræ¨¡å‹çš„ç ”ç©¶ä¸­ï¼Œä¼šå‡ºç°ä¸€äº›æœ¯è¯­ï¼šæ¶æ„Architectureå’Œæ£€æŸ¥ç‚¹checkpointä»¥åŠModelã€‚ è¿™äº›æœ¯è¯­çš„å«ä¹‰ç•¥æœ‰ä¸åŒï¼š\n",
    "\n",
    "Architectureï¼šå®šä¹‰äº†æ¨¡å‹çš„åŸºæœ¬ç»“æ„å’ŒåŸºæœ¬è¿ç®—\n",
    "\n",
    "checkpointï¼šæ¨¡å‹çš„æŸä¸ªè®­ç»ƒçŠ¶æ€ï¼ŒåŠ è½½æ­¤checkpointä¼šåŠ è½½æ­¤æ—¶çš„æƒé‡ã€‚ï¼ˆè®­ç»ƒæ—¶å¯ä»¥é€‰æ‹©è‡ªåŠ¨ä¿å­˜checkpointï¼‰\n",
    "\n",
    "Model:è¿™æ˜¯ä¸€ä¸ªæ€»ç§°ï¼Œä¸åƒâ€œæ¶æ„â€æˆ–â€œæ£€æŸ¥ç‚¹â€é‚£æ ·ç²¾ç¡®ï¼Œå®ƒå¯ä»¥åŒæ—¶è¡¨ç¤ºä¸¤è€…ã€‚ å½“éœ€è¦å‡å°‘æ­§ä¹‰æ—¶ï¼Œæœ¬è¯¾ç¨‹å°†æŒ‡å®šæ¶æ„æˆ–æ£€æŸ¥ç‚¹ã€‚<br>\n",
    "ä¾‹å¦‚ï¼ŒBERT æ˜¯ä¸€ç§ Architecturesï¼Œè€Œ bert-base-casedï¼ˆè°·æ­Œå›¢é˜Ÿä¸º BERT çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬è®­ç»ƒçš„ä¸€ç»„æƒé‡ï¼‰æ˜¯ä¸€ä¸ªcheckpointsã€‚ ä½†æ˜¯ï¼Œå¯ä»¥è¯´â€œthe BERT modelâ€å’Œâ€œthe bert-base-cased modelâ€ã€‚\n",
    "\n",
    "***checkpointæ¦‚å¿µåœ¨å¤§æ•°æ®é‡Œé¢è¯´çš„æ¯”è¾ƒå¤šã€‚æ¨¡å‹åœ¨è®­ç»ƒæ—¶å¯ä»¥è®¾ç½®è‡ªåŠ¨ä¿å­˜äºæŸä¸ªæ—¶é—´ç‚¹ï¼ˆæ¯”å¦‚æ¨¡å‹è®­ç»ƒäº†ä¸€è½®epochï¼Œæ›´æ–°äº†å‚æ•°ï¼Œå°†è¿™ä¸ªçŠ¶æ€çš„æ¨¡å‹ä¿å­˜ä¸‹æ¥ï¼Œä¸ºä¸€ä¸ªcheckpointã€‚ï¼‰\n",
    "æ‰€ä»¥æ¯ä¸ªcheckpointå¯¹åº”æ¨¡å‹çš„ä¸€ä¸ªçŠ¶æ€ï¼Œä¸€ç»„æƒé‡ã€‚å¤§æ•°æ®ä¸­æ£€æŸ¥ç‚¹æ˜¯ä¸€ä¸ªæ•°æ®åº“äº‹ä»¶ï¼Œå­˜åœ¨çš„æ ¹æœ¬æ„ä¹‰æ˜¯å‡å°‘å´©æºƒæ—¶é—´ã€‚å³å‡å°‘å› ä¸ºæ„å¤–æƒ…å†µæ•°æ®åº“å´©æºƒåé‡æ–°æ¢å¤çš„æ—¶é—´ã€‚***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842779d3",
   "metadata": {},
   "source": [
    "### The Inference API\n",
    "[Model Hub](https://huggingface.co/models)ï¼ˆæ¨¡å‹ä¸­å¿ƒï¼‰åŒ…å«å¤šè¯­è¨€æ¨¡å‹çš„checkpointsã€‚æ‚¨å¯ä»¥é€šè¿‡å•å‡»è¯­è¨€æ ‡ç­¾æ¥ä¼˜åŒ–å¯¹æ¨¡å‹çš„æœç´¢ï¼Œç„¶åé€‰æ‹©ç”Ÿæˆå¦ä¸€ç§è¯­è¨€æ–‡æœ¬çš„æ¨¡å‹ã€‚ \n",
    "\n",
    "é€šè¿‡å•å‡»é€‰æ‹©æ¨¡å‹åï¼Œæ‚¨ä¼šçœ‹åˆ°æœ‰ä¸€ä¸ªå°éƒ¨ä»¶â€”â€”Inference APIï¼ˆæ”¯æŒåœ¨çº¿è¯•ç”¨ï¼‰ã€‚å³æ‚¨å¯ä»¥ç›´æ¥åœ¨æ­¤é¡µé¢ä¸Šä½¿ç”¨å„ç§æ¨¡å‹ï¼Œé€šè¿‡è¾“å…¥è‡ªå®šä¹‰æ–‡æœ¬å°±å¯ä»¥çœ‹åˆ°æ¨¡å‹å¤„ç†è¾“å…¥æ•°æ®åçš„ç»“æœã€‚ é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹è½½æ¨¡å‹ä¹‹å‰å¿«é€Ÿæµ‹è¯•æ¨¡å‹çš„åŠŸèƒ½ã€‚\n",
    "![DistilBERT base model (uncased)](https://img-blog.csdnimg.cn/0edebca3ab8248b4b2bac88f88ab79c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA56We5rSb5Y2O,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa220c87",
   "metadata": {},
   "source": [
    "## 2. ç”¨pipelineå¤„ç†NLPé—®é¢˜\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ Transformer æ¨¡å‹å¯ä»¥åšä»€ä¹ˆï¼Œå¹¶ä½¿ç”¨ ğŸ¤— Transformers åº“ä¸­çš„ç¬¬ä¸€ä¸ªå·¥å…·ï¼šç®¡é“pipelineã€‚\n",
    "\n",
    ">ğŸ¤— [Transformers åº“](https://github.com/huggingface/transformers)æä¾›äº†åˆ›å»ºå’Œä½¿ç”¨å…±äº«æ¨¡å‹çš„åŠŸèƒ½.ã€‚[Model Hub](https://huggingface.co/models)åŒ…å«æ•°åƒä¸ªæ‰€æœ‰äººéƒ½å¯ä»¥ä¸‹è½½å’Œä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚ æ‚¨ä¹Ÿå¯ä»¥å°†è‡ªå·±çš„æ¨¡å‹ä¸Šä¼ åˆ° Hubï¼\n",
    "\n",
    "ğŸ¤— Transformers åº“ä¸­æœ€åŸºæœ¬çš„å¯¹è±¡æ˜¯pipelineã€‚ å®ƒå°†æ¨¡å‹ä¸å…¶å¿…è¦çš„é¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤è¿æ¥èµ·æ¥ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç›´æ¥è¾“å…¥ä»»ä½•æ–‡æœ¬å¹¶è·å¾—å¯ç†è§£çš„ç­”æ¡ˆï¼š\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "```\n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9598047137260437}]\n",
    "```\n",
    "æˆ‘ä»¬ç”šè‡³å¯ä»¥ä¼ å…¥å‡ ä¸ªå¥å­ï¼\n",
    "```python\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])\n",
    "```\n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
    " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]\n",
    " ```\n",
    "é»˜è®¤æƒ…å†µä¸‹ï¼Œæ­¤ç®¡é“é€‰æ‹©ä¸€ä¸ªç‰¹å®šçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å·²é’ˆå¯¹è‹±è¯­æƒ…æ„Ÿåˆ†æè¿›è¡Œäº†å¾®è°ƒã€‚ åˆ›å»ºåˆ†ç±»å™¨å¯¹è±¡æ—¶ï¼Œå°†ä¸‹è½½å¹¶ç¼“å­˜æ¨¡å‹ã€‚ å¦‚æœæ‚¨é‡æ–°è¿è¡Œè¯¥å‘½ä»¤ï¼Œåˆ™å°†ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹ï¼Œæ— éœ€å†æ¬¡ä¸‹è½½æ¨¡å‹ã€‚\n",
    "\n",
    "å°†ä¸€äº›æ–‡æœ¬ä¼ é€’åˆ°ç®¡é“æ—¶æ¶‰åŠä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š\n",
    "\n",
    "1. é¢„å¤„ç†ï¼šæ–‡æœ¬è¢«é¢„å¤„ç†ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚\n",
    "2. è¾“å…¥æ¨¡å‹ï¼šæ„å»ºæ¨¡å‹ï¼Œå¹¶å°†é¢„å¤„ç†çš„è¾“å…¥ä¼ é€’ç»™æ¨¡å‹ã€‚\n",
    "3. åå¤„ç†ï¼šæ¨¡å‹çš„é¢„æµ‹æ˜¯ç»è¿‡åå¤„ç†çš„ï¼Œå› æ­¤æ‚¨å¯ä»¥ç†è§£å®ƒä»¬ã€‚\n",
    "\n",
    "ç›®å‰å¯ç”¨çš„ä¸€äº›ç®¡é“æ˜¯ï¼š\n",
    "- feature-extraction (è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º)\n",
    "- fill-maskå¡«å……ç»™å®šæ–‡æœ¬ä¸­çš„ç©ºç™½ï¼ˆå®Œå½¢å¡«ç©ºï¼‰\n",
    "- ner (named entity recognition)è¯æ€§æ ‡æ³¨\n",
    "- question-answeringé—®ç­”\n",
    "- sentiment-analysisæƒ…æ„Ÿåˆ†æ\n",
    "- summarizationæ‘˜è¦ç”Ÿæˆ\n",
    "- text-generationæ–‡æœ¬ç”Ÿæˆ\n",
    "- translationç¿»è¯‘\n",
    "- zero-shot-classificationé›¶æ ·æœ¬åˆ†ç±»\n",
    "\n",
    "æ‚¨ä¹Ÿå¯ä»¥ä» Hub ä¸­é’ˆå¯¹ç‰¹å®šä»»åŠ¡æ¥é€‰æ‹©ç‰¹å®šæ¨¡å‹çš„ç®¡é“ ä¾‹å¦‚ï¼Œæ–‡æœ¬ç”Ÿæˆã€‚è½¬åˆ° [Model Hub](https://huggingface.co/models)å¹¶å•å‡»å·¦ä¾§çš„ç›¸åº”æ ‡ç­¾ï¼Œé¡µé¢å°†ä¼šä»…æ˜¾ç¤ºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡æ”¯æŒçš„æ¨¡å‹ã€‚\n",
    "(***é™¤äº†æ¨¡å‹è¦åŒ¹é…ä»»åŠ¡ï¼Œæ›´è¿›ä¸€æ­¥è€ƒè™‘çš„å› ç´ ä¹‹ä¸€æ˜¯ï¼šé¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ•°æ®é›†ï¼Œè¦å°½å¯èƒ½çš„æ¥è¿‘ä½ éœ€è¦å¤„ç†çš„ä»»åŠ¡æ‰€åŒ…å«çš„æ•°æ®é›†ï¼Œä¸¤ä¸ªæ•°æ®é›†è¶Šæ¥è¿‘è¶Šå¥½ã€‚***ï¼‰ \n",
    "\n",
    "Transformers pipeline API å¯ä»¥å¤„ç†ä¸åŒçš„ NLP ä»»åŠ¡ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®Œæ•´æ¶æ„ï¼Œä¹Ÿå¯ä»¥ä»…ä½¿ç”¨ç¼–ç å™¨æˆ–è§£ç å™¨ï¼Œå…·ä½“å–å†³äºæ‚¨è¦è§£å†³çš„ä»»åŠ¡ç±»å‹ã€‚ ä¸‹è¡¨æ€»ç»“äº†è¿™ä¸€ç‚¹ï¼š\n",
    "\n",
    " æ¨¡å‹    | ä¾‹å­ | ä»»åŠ¡\n",
    "-------- | ----- |----- \n",
    "Encoder  | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa |å¥å­åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æŠ½å–å¼é—®ç­”\n",
    "Decoder  | CTRL, GPT, GPT-2, Transformer XL |æ–‡æœ¬ç”Ÿæˆ\n",
    "Encoder-decoder  | BART, T5, Marian, mBART |æ‘˜è¦ç”Ÿæˆã€ç¿»è¯‘ã€ç”Ÿæˆå¼é—®ç­”\n",
    "\n",
    "ä»¥ä¸Šæ˜¾ç¤ºçš„pipelineä¸»è¦ç”¨äºæ¼”ç¤ºç›®çš„ã€‚ å®ƒä»¬æ˜¯ä¸ºç‰¹å®šä»»åŠ¡ç¼–ç¨‹çš„ï¼Œä¸èƒ½æ‰§è¡Œå®ƒä»¬çš„å˜ä½“ã€‚ åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæ‚¨å°†äº†è§£ç®¡é“å†…éƒ¨çš„å†…å®¹ä»¥åŠå¦‚ä½•è‡ªå®šä¹‰å…¶è¡Œä¸ºã€‚\n",
    ">ä¸Šé¢è¿™å‡ ç§ç®¡é“çš„ç®€å•ç¤ºä¾‹å¯ä»¥æŸ¥çœ‹â€”â€”[Hugging Faceä¸»é¡µè¯¾ç¨‹ç¬¬ä¸€ç¯‡ã€ŠTransformer modelsã€‹](https://blog.csdn.net/qq_56591814/article/details/120124306)ã€‚\n",
    ">æˆ–å•å‡»[Open in Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter1/section3.ipynb)ä»¥æ‰“å¼€åŒ…å«å…¶å®ƒç®¡é“åº”ç”¨ä»£ç ç¤ºä¾‹çš„ Google Colab ç¬”è®°æœ¬ã€‚\n",
    "å¦‚æœæ‚¨æƒ³åœ¨æœ¬åœ°è¿è¡Œç¤ºä¾‹ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹[è®¾ç½®](https://huggingface.co/course/chapter0)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaed469",
   "metadata": {},
   "source": [
    "## 3. Behind the pipeline\n",
    ">æœ¬èŠ‚ä»£ç :[Open in Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section2_pt.ipynb) (PyTorch)<br>\n",
    ">YouTubeè§†é¢‘ï¼š[what happend inside the pipeline function](https://youtu.be/1pedAIvTWXk)\n",
    "\n",
    "è®©æˆ‘ä»¬ä»ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­å¼€å§‹ï¼Œçœ‹çœ‹å½“æˆ‘ä»¬åœ¨ç¬¬1èŠ‚ä¸­æ‰§è¡Œä»¥ä¸‹ä»£ç æ—¶ï¼Œå¹•åå‘ç”Ÿäº†ä»€ä¹ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b855a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b53f5",
   "metadata": {},
   "source": [
    "æ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬ 1 ç« ä¸­çœ‹åˆ°çš„ï¼Œè¿™ä¸ªç®¡é“å°†ä¸‰ä¸ªæ­¥éª¤ç»„åˆåœ¨ä¸€èµ·ï¼šé¢„å¤„ç†ã€é€šè¿‡æ¨¡å‹ä¼ é€’è¾“å…¥å’Œåå¤„ç†ï¼š\n",
    "![full_nlp_pipeline ](https://img-blog.csdnimg.cn/7f19b775bfe94fa0bb9e35d883567e16.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA56We5rSb5Y2O,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)\n",
    "\n",
    "è®©æˆ‘ä»¬å¿«é€Ÿæµè§ˆä¸€ä¸‹è¿™äº›å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcc38d",
   "metadata": {},
   "source": [
    "### tokenizeré¢„å¤„ç†\n",
    "ä¸å…¶ä»–ç¥ç»ç½‘ç»œä¸€æ ·ï¼ŒTransformer æ¨¡å‹ä¸èƒ½ç›´æ¥å¤„ç†åŸå§‹æ–‡æœ¬ï¼Œå› æ­¤æˆ‘ä»¬ç®¡é“çš„ç¬¬ä¸€æ­¥æ˜¯å°†æ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•°å­—ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåˆ†è¯å™¨tokenizerï¼Œå®ƒå°†è´Ÿè´£ï¼š\n",
    "\n",
    "- å°†è¾“å…¥æ‹†åˆ†ä¸ºç§°ä¸ºæ ‡è®°çš„å•è¯ã€å­è¯subwordæˆ–ç¬¦å·symbolsï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ï¼‰\n",
    "- å°†æ¯ä¸ªæ ‡è®°æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°\n",
    "- æ·»åŠ å¯èƒ½å¯¹æ¨¡å‹æœ‰ç”¨çš„å…¶ä»–è¾“å…¥\n",
    "\n",
    "ä½¿ç”¨ AutoTokenizer ç±»åŠå…¶ from_pretrained æ–¹æ³•ï¼Œä»¥ä¿è¯æ‰€æœ‰è¿™äº›é¢„å¤„ç†éƒ½ä»¥ä¸æ¨¡å‹é¢„è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„æ–¹å¼å®Œæˆã€‚è®¾å®šæ¨¡å‹çš„ checkpointåç§°ï¼Œå®ƒä¼šè‡ªåŠ¨è·å–ä¸æ¨¡å‹çš„Tokenizerå…³è”çš„æ•°æ®å¹¶ç¼“å­˜å®ƒï¼ˆæ‰€ä»¥å®ƒåªåœ¨ä½ ç¬¬ä¸€æ¬¡è¿è¡Œä¸‹é¢çš„ä»£ç æ—¶ä¸‹è½½ï¼‰ã€‚\n",
    "\n",
    "ç”±äºæƒ…æ„Ÿåˆ†æç®¡é“çš„é»˜è®¤æ£€æŸ¥ç‚¹æ˜¯ [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)ï¼Œæˆ‘ä»¬å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤å¾—åˆ°æˆ‘ä»¬éœ€è¦çš„tokenizerï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07963015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11bc2dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#return_tensors=\"pt\"è¡¨ç¤ºè¿”å›Pytorchå¼ é‡ã€‚æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ä¹‹åå¿…é¡»å†è½¬æ¢æˆå¼ é‡tensorsæ‰èƒ½è¾“å…¥æ¨¡å‹ã€‚\n",
    "#padding=Trueè¡¨ç¤ºå¡«å……è¾“å…¥åºåˆ—åˆ°æœ€å¤§é•¿åº¦ï¼Œtruncation=Trueè¡¨ç¤ºè¿‡é•¿åºåˆ—è¢«æˆªæ–­\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ade14",
   "metadata": {},
   "source": [
    "### é€‰æ‹©æ¨¡å‹\n",
    "æˆ‘ä»¬å¯ä»¥åƒä½¿ç”¨åˆ†è¯å™¨ä¸€æ ·ä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚ ğŸ¤— Transformers æä¾›äº†ä¸€ä¸ª AutoModel ç±»ï¼Œå®ƒä¹Ÿæœ‰ä¸€ä¸ª from_pretrained æ–¹æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad74b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71608d25",
   "metadata": {},
   "source": [
    "AutoModel ç±»åŠå…¶æ‰€æœ‰ç›¸å…³ç±»å®é™…ä¸Šæ˜¯åº“ä¸­å„ç§å¯ç”¨æ¨¡å‹çš„ç®€å•åŒ…è£…å™¨ã€‚ å®ƒå¯ä»¥è‡ªåŠ¨ä¸ºæ‚¨çš„checkpointçŒœæµ‹åˆé€‚çš„æ¨¡å‹æ¶æ„ï¼Œç„¶åä½¿ç”¨è¯¥æ¶æ„å®ä¾‹åŒ–æ¨¡å‹ã€‚ï¼ˆ***å³AutoModel ç±»å¯ä»¥ä»checkpointå®ä¾‹åŒ–ä»»ä½•æ¨¡å‹ï¼Œè€Œä¸”è¿™æ˜¯ä¸€ç§æ›´å¥½çš„å®ä¾‹åŒ–æ¨¡å‹æ–¹æ³•ã€‚æ„å»ºæ¨¡å‹è¿˜æœ‰å¦ä¸€ç§æ–¹æ³•ï¼Œæ”¾åœ¨æ–‡æœ«ã€‚***ï¼‰\n",
    "\n",
    "åœ¨æ­¤ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬ä¸‹è½½äº†ä¹‹å‰åœ¨ç®¡é“ä¸­ä½¿ç”¨çš„ç›¸åŒcheckpointï¼ˆå®ƒå®é™…ä¸Šåº”è¯¥å·²ç»è¢«ç¼“å­˜ï¼‰å¹¶ç”¨å®ƒå®ä¾‹åŒ–äº†ä¸€ä¸ªæ¨¡å‹ã€‚ä½†æ˜¯è¿™ä¸ªæ¶æ„åªåŒ…å«åŸºæœ¬çš„ Transformer æ¨¡å—ï¼šç»™å®šä¸€äº›è¾“å…¥ï¼Œå®ƒè¾“å‡ºæˆ‘ä»¬ç§°ä¹‹ä¸ºéšè—çŠ¶æ€hidden statesçš„ä¸œè¥¿ã€‚è™½ç„¶è¿™äº›éšè—çŠ¶æ€æœ¬èº«å°±å¾ˆæœ‰ç”¨ï¼Œä½†å®ƒä»¬é€šå¸¸æ˜¯æ¨¡å‹å¦ä¸€éƒ¨åˆ†ï¼ˆmodel headï¼‰çš„è¾“å…¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4abea6",
   "metadata": {},
   "source": [
    "### Model heads\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹ä½“ç³»ç»“æ„æ‰§è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œä½†æ˜¯æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸ä¹‹å…³è”çš„ä¸åŒçš„Model headsã€‚\n",
    "\n",
    "Model heads:å°†éšè—çŠ¶æ€çš„é«˜ç»´å‘é‡ï¼ˆä¹Ÿå°±æ˜¯logitså‘é‡ï¼‰ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬æŠ•å½±åˆ°ä¸åŒçš„ç»´åº¦ä¸Šã€‚ å®ƒä»¬é€šå¸¸ç”±ä¸€ä¸ªæˆ–å‡ ä¸ªçº¿æ€§å±‚ç»„æˆï¼š\n",
    "![transformer_and_head](https://img-blog.csdnimg.cn/9156c4e09d184e7c88732e60ae59e05e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA56We5rSb5Y2O,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)\n",
    "åœ¨æ­¤å›¾ä¸­ï¼Œæ¨¡å‹ç”±å…¶embeddings layerå’Œåç»­å±‚è¡¨ç¤ºã€‚è¾“å…¥æ•°æ®ç»è¿‡embeddings layerè¾“å‡ºlogitså‘é‡ä»¥äº§ç”Ÿå¥å­çš„æœ€ç»ˆè¡¨ç¤ºã€‚\n",
    "\n",
    "ğŸ¤— Transformers ä¸­æœ‰è®¸å¤šä¸åŒçš„æ¶æ„å¯ç”¨ï¼Œæ¯ä¸€ç§æ¶æ„éƒ½å›´ç»•ç€å¤„ç†ç‰¹å®šä»»åŠ¡è€Œè®¾è®¡ã€‚ ä¸‹é¢åˆ—ä¸¾äº†éƒ¨åˆ†Model headsï¼š\n",
    "* Model (retrieve the hidden states)\n",
    "* ForCausalLM\n",
    "* ForMaskedLM\n",
    "* ForMultipleChoice\n",
    "* ForQuestionAnswering\n",
    "* ForSequenceClassification\n",
    "* ForTokenClassification\n",
    "* and others ğŸ¤—\n",
    "\n",
    "ä»¥æƒ…æ„Ÿåˆ†ç±»ä¸ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¸¦æœ‰åºåˆ—åˆ†ç±»çš„Model headï¼ˆèƒ½å¤Ÿå°†å¥å­åˆ†ç±»ä¸ºæ­£é¢æˆ–è´Ÿé¢ï¼‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šä½¿ç”¨ AutoModel ç±»ï¼Œè€Œæ˜¯ä½¿ç”¨ AutoModelForSequenceClassificationï¼š\n",
    "\n",
    "ï¼ˆ***ä¹Ÿå°±æ˜¯è¯´å‰é¢å†™çš„model = AutoModel.from_pretrained(checkpoint)å¹¶ä¸èƒ½å¾—åˆ°æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡çš„ç»“æœï¼Œå› ä¸ºæ²¡æœ‰åŠ è½½Model head***ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28740d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
       "          2607,  2026,  2878,  2166,  1012,   102],\n",
       "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71e0e9",
   "metadata": {},
   "source": [
    "model headå°†æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„é«˜ç»´å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºåŒ…å«ä¸¤ä¸ªå€¼ï¼ˆæ¯ä¸ªæ ‡ç­¾ä¸€ä¸ªï¼‰çš„å‘é‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e54b2e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de60b188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5cc94",
   "metadata": {},
   "source": [
    "ç”±äºæˆ‘ä»¬åªæœ‰ä¸¤ä¸ªå¥å­å’Œä¸¤ä¸ªæ ‡ç­¾ï¼Œå› æ­¤æˆ‘ä»¬ä»æ¨¡å‹ä¸­å¾—åˆ°çš„ç»“æœæ˜¯ 2 x 2 çš„å½¢çŠ¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a98c0",
   "metadata": {},
   "source": [
    "### Post-processingåå¤„ç†\n",
    "æˆ‘ä»¬ä»æ¨¡å‹ä¸­è·å¾—çš„ä½œä¸ºè¾“å‡ºçš„å€¼æœ¬èº«å¹¶ä¸ä¸€å®šæœ‰æ„ä¹‰ã€‚ è®©æˆ‘ä»¬æ¥çœ‹çœ‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed37d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be292",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹äº†ç¬¬ä¸€ä¸ªå¥å­ç»“æœ [-1.5607, 1.6123] å’Œç¬¬äºŒä¸ªå¥å­çš„ç»“æœ [4.1692, -3.3464]ã€‚ è¿™äº›ä¸æ˜¯æ¦‚ç‡ï¼Œè€Œæ˜¯ logitsï¼Œå³æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„åŸå§‹éæ ‡å‡†åŒ–åˆ†æ•°ã€‚ è¦è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå®ƒä»¬éœ€è¦ç»è¿‡ä¸€ä¸ª SoftMax å±‚ã€‚æ‰€æœ‰ğŸ¤— Transformers æ¨¡å‹éƒ½è¾“å‡º logitsï¼Œè¿™æ˜¯å› ä¸ºè®­ç»ƒçš„æŸå¤±å‡½æ•°ä¸€èˆ¬ä¼šå°†æœ€åä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆæ¯”å¦‚SoftMaxï¼‰å’Œå®é™…çš„äº¤å‰ç†µæŸå¤±å‡½æ•°ç›¸èåˆã€‚<br>\n",
    "ï¼ˆ***è¡¥å……ï¼šåœ¨Pytorché‡Œé¢ï¼Œäº¤å‰ç†µæŸå¤±CElossä¸æ˜¯æ•°å­¦ä¸Šçš„äº¤å‰ç†µæŸå¤±ï¼ˆNLLLossï¼‰ã€‚Pytorchçš„CrossEntropyLosså°±æ˜¯æŠŠSoftmaxâ€“Logâ€“NLLLossåˆå¹¶æˆä¸€æ­¥ã€‚è¯¦ç»†å†…å®¹å¯ä»¥å‚è€ƒçŸ¥ä¹æ–‡ç« [ã€Šå¦‚ä½•ç†è§£NLLLoss?ã€‹](https://zhuanlan.zhihu.com/p/30187567)***ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971038f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903159a3",
   "metadata": {},
   "source": [
    "è¿™æ¬¡è¾“å‡ºæ˜¯å¯è¯†åˆ«çš„æ¦‚ç‡åˆ†æ•°ã€‚\n",
    "\n",
    "è¦è·å¾—æ¯ä¸ªä½ç½®å¯¹åº”çš„æ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ¨¡å‹é…ç½®çš„ id2label å±æ€§ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902d866c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7edf7",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œè¯¥æ¨¡å‹é¢„æµ‹äº†ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "ç¬¬ä¸€å¥ï¼šNEGATIVEï¼š0.0402ï¼ŒPOSITIVEï¼š0.9598<br>\n",
    "ç¬¬äºŒå¥ï¼šNEGATIVEï¼š0.9995ï¼ŒPOSITIVEï¼š0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1a9f2",
   "metadata": {},
   "source": [
    "## 4. æ„å»ºTrainer APIå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹\n",
    ">æœ¬èŠ‚ä»£ç ï¼š[Open in Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb)ï¼ˆPyTorchï¼‰ï¼Œå»ºè®®ç‚¹æ­¤è¿›è¡Œæµ‹è¯•ã€‚colabä¸ŠåŠ è½½æ•°æ®é›†éå¸¸å¿«ï¼Œè®¾ç½®GPUåè®­ç»ƒä¹Ÿæ¯”è¾ƒå¿«ã€‚\n",
    ">æ‰“å¼€åé€‰æ‹©å·¦ä¸Šæ–¹â€œä¿®æ”¹â€é€‰é¡¹å¡ï¼Œç‚¹å‡»ç¬”è®°æœ¬è®¾ç½®-ç¡¬ä»¶åŠ é€Ÿå™¨Noneæ”¹æˆGPUå°±è¡Œã€‚\n",
    "\n",
    "åœ¨ç¬¬3èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨åˆ†è¯å™¨å’Œé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚ ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æƒ³ä¸ºè‡ªå·±çš„æ•°æ®é›†å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹æ€ä¹ˆåŠï¼Ÿ è¿™å°±æ˜¯æœ¬ç« çš„ä¸»é¢˜ï¼ ä½ å°†å­¦ä¹ ï¼š\n",
    "\n",
    "- å¦‚ä½•ä»Model Hub å‡†å¤‡å¤§å‹æ•°æ®é›†\n",
    "- å¦‚ä½•ä½¿ç”¨high-level Trainer APIæ¥å¾®è°ƒæ¨¡å‹\n",
    "- å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯a custom training loop\n",
    "- å¦‚ä½•åˆ©ç”¨ ğŸ¤— Accelerate åº“åœ¨ä»»ä½•åˆ†å¸ƒå¼è®¾ç½®ä¸Šè½»æ¾è¿è¡Œè¯¥custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f3cbf",
   "metadata": {},
   "source": [
    "### ä»Hubä¸Šä¸‹è½½dataset\n",
    ">Youtube è§†é¢‘ï¼š[Hugging Face Datasets Overview](https://youtu.be/_BZearw7f0w)ï¼ˆpytorchï¼‰\n",
    "\n",
    "Hub ä¸ä»…åŒ…å«æ¨¡å‹ï¼›è¿˜å«æœ‰å¤šä¸ª[datasets](https://huggingface.co/datasets)ï¼Œè¿™äº›datasetsæœ‰å¾ˆå¤šä¸åŒçš„è¯­è¨€ã€‚æˆ‘ä»¬å»ºè®®æ‚¨åœ¨å®Œæˆæœ¬èŠ‚åå°è¯•åŠ è½½å’Œå¤„ç†æ–°æ•°æ®é›†ï¼ˆ[å‚è€ƒæ–‡æ¡£](https://huggingface.co/docs/datasets/loading_datasets.html#from-the-huggingface-hub)ï¼‰ã€‚ \n",
    "\n",
    " MRPC æ•°æ®é›†æ˜¯æ„æˆ [GLUE åŸºå‡†](https://gluebenchmark.com/)çš„ 10 ä¸ªæ•°æ®é›†ä¹‹ä¸€ã€‚è€ŒGLUE åŸºå‡†æ˜¯ä¸€ç§å­¦æœ¯åŸºå‡†ï¼Œç”¨äºè¡¡é‡ ML æ¨¡å‹åœ¨ 10 ä¸ªä¸åŒæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚\n",
    "\n",
    "ğŸ¤— Datasetsåº“æä¾›äº†ä¸€ä¸ªéå¸¸ç®€å•çš„å‘½ä»¤æ¥ä¸‹è½½å’Œç¼“å­˜Hubä¸Šçš„datasetã€‚ æˆ‘ä»¬å¯ä»¥åƒè¿™æ ·ä¸‹è½½ MRPC æ•°æ®é›†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d06a156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64030e57f17a47eebfe69d6f03539690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=7777.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fad1c6baf0f457695b16ef505be12dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=4473.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273effe22d4f41afb0066922d8a10361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20pxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcfb381cbeb48dab962a58065d0e634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20pxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d42b5d9ed754d1aab22eb3e6731f8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20pxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab9929",
   "metadata": {},
   "source": [
    "**æŠ¥é”™ï¼š ValueError: check_hostname requires server_hostname  çš„è§£å†³æ–¹æ³•**\n",
    "\n",
    "pip install urllib3==1.25.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a471a",
   "metadata": {},
   "source": [
    "è¿™æ ·å°±å¾—åˆ°ä¸€ä¸ªDatasetDictå¯¹è±¡ï¼ŒåŒ…å«è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œè®­ç»ƒé›†ä¸­æœ‰3,668 ä¸ªå¥å­å¯¹ï¼ŒéªŒè¯é›†ä¸­æœ‰408å¯¹ï¼Œæµ‹è¯•é›†ä¸­æœ‰1,725 å¯¹ã€‚æ¯ä¸ªå¥å­å¯¹åŒ…å«å››åˆ—æ•°æ®ï¼š'sentence1', 'sentence2', 'label'å’Œ 'idx'ã€‚\n",
    "\n",
    "load_dataset æ–¹æ³•, å¯ä»¥ä»ä¸åŒçš„åœ°æ–¹æ„å»ºæ•°æ®é›†<br>\n",
    "- from the HuggingFace Hub,\n",
    "- from local files, å¦‚CSV/JSON/text/pandas files\n",
    "- from in-memory data like python dict or a pandas dataframe.\n",
    "\n",
    "ä¾‹å¦‚ï¼š datasets = load_dataset(\"text\", data_files={\"train\": path_to_train.txt, \"validation\": path_to_validation.txt} å…·ä½“å¯ä»¥[å‚è€ƒæ–‡æ¡£](https://link.zhihu.com/?target=https%3A//huggingface.co/docs/datasets/loading_datasets.html%23from-local-files)\n",
    "\n",
    "load_datasetå‘½ä»¤ä¸‹è½½å¹¶ç¼“å­˜æ•°æ®é›†ï¼Œé»˜è®¤åœ¨ ~/.cache/huggingface/dataset ä¸­ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½® HF_HOME ç¯å¢ƒå˜é‡æ¥è‡ªå®šä¹‰ç¼“å­˜æ–‡ä»¶å¤¹ã€‚\n",
    "\n",
    "å’Œå­—å…¸ä¸€æ ·ï¼Œraw_datasets å¯ä»¥é€šè¿‡ç´¢å¼•è®¿é—®å…¶ä¸­çš„å¥å­å¯¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d749fddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': 1,\n",
       " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b1c4011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>He said the foodservice pie business doesn 't ...</td>\n",
       "      <td>\" The foodservice pie business does not fit ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>Magnarelli said Racicot hated the Iraqi regime...</td>\n",
       "      <td>His wife said he was \" 100 percent behind Geor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>The dollar was at 116.92 yen against the yen ,...</td>\n",
       "      <td>The dollar was at 116.78 yen JPY = , virtually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>The AFL-CIO is waiting until October to decide...</td>\n",
       "      <td>The AFL-CIO announced Wednesday that it will d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>No dates have been set for the civil or the cr...</td>\n",
       "      <td>No dates have been set for the criminal or civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4023</td>\n",
       "      <td>0</td>\n",
       "      <td>Their contract will expire at 12 : 01 a.m. Wed...</td>\n",
       "      <td>\" It has outraged the membership , \" said Rian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4028</td>\n",
       "      <td>1</td>\n",
       "      <td>But plaque volume increased by 2.7 percent in ...</td>\n",
       "      <td>The volume of plaque in Pravachol patients ' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4040</td>\n",
       "      <td>1</td>\n",
       "      <td>Today in the US , the book - kept under wraps ...</td>\n",
       "      <td>Tomorrow the book , kept under wraps by G. P. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4049</td>\n",
       "      <td>0</td>\n",
       "      <td>The S &amp; P / TSX composite rose 87.74 points on...</td>\n",
       "      <td>On the week , the Dow Jones industrial average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4053</td>\n",
       "      <td>1</td>\n",
       "      <td>Ex-KGB agent Putin added that the Beatles were...</td>\n",
       "      <td>In Soviet times the Beatles ' music \" was cons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idx  label                                          sentence1  \\\n",
       "0       9      1  He said the foodservice pie business doesn 't ...   \n",
       "1      18      0  Magnarelli said Racicot hated the Iraqi regime...   \n",
       "2      25      0  The dollar was at 116.92 yen against the yen ,...   \n",
       "3      32      1  The AFL-CIO is waiting until October to decide...   \n",
       "4      33      0  No dates have been set for the civil or the cr...   \n",
       "..    ...    ...                                                ...   \n",
       "403  4023      0  Their contract will expire at 12 : 01 a.m. Wed...   \n",
       "404  4028      1  But plaque volume increased by 2.7 percent in ...   \n",
       "405  4040      1  Today in the US , the book - kept under wraps ...   \n",
       "406  4049      0  The S & P / TSX composite rose 87.74 points on...   \n",
       "407  4053      1  Ex-KGB agent Putin added that the Beatles were...   \n",
       "\n",
       "                                             sentence2  \n",
       "0    \" The foodservice pie business does not fit ou...  \n",
       "1    His wife said he was \" 100 percent behind Geor...  \n",
       "2    The dollar was at 116.78 yen JPY = , virtually...  \n",
       "3    The AFL-CIO announced Wednesday that it will d...  \n",
       "4    No dates have been set for the criminal or civ...  \n",
       "..                                                 ...  \n",
       "403  \" It has outraged the membership , \" said Rian...  \n",
       "404  The volume of plaque in Pravachol patients ' a...  \n",
       "405  Tomorrow the book , kept under wraps by G. P. ...  \n",
       "406  On the week , the Dow Jones industrial average...  \n",
       "407  In Soviet times the Beatles ' music \" was cons...  \n",
       "\n",
       "[408 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "validation=pd.DataFrame(raw_datasets['validation'])\n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89139602",
   "metadata": {},
   "source": [
    "å¯è§æ ‡ç­¾å·²ç»æ˜¯æ•´æ•°ï¼Œä¸éœ€è¦å†åšä»»ä½•é¢„å¤„ç†ã€‚é€šè¿‡raw_train_datasetçš„featureså±æ€§å¯ä»¥çŸ¥é“æ¯ä¸€åˆ—çš„ç±»å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "debb009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c73e8d",
   "metadata": {},
   "source": [
    "labelæ˜¯ ClassLabel ç±»å‹ï¼Œlabel=1è¡¨ç¤ºè¿™å¯¹å¥å­äº’ä¸ºparaphrasesï¼Œlabel=0è¡¨ç¤ºå¥å­å¯¹æ„æ€ä¸ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244e813",
   "metadata": {},
   "source": [
    "### æ•°æ®é›†é¢„å¤„ç†\n",
    ">YouTubeè§†é¢‘[ã€ŠPreprocessing sentence pairsã€‹](https://youtu.be/0u3ioSwev3s)\n",
    "\n",
    "é€šè¿‡tokenizerå¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹èƒ½ç†è§£çš„æ•°å­—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bcde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72188c34",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0747c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8d07d",
   "metadata": {},
   "source": [
    "æ‰€ä»¥å°†å¥å­å¯¹åˆ—è¡¨ä¼ ç»™tokenizerï¼Œå°±å¯ä»¥å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œåˆ†è¯å¤„ç†ã€‚å› æ­¤ï¼Œé¢„å¤„ç†è®­ç»ƒæ•°æ®é›†çš„ä¸€ç§æ–¹æ³•æ˜¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f03a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenizer(\n",
    "    raw_datasets[\"train\"][\"sentence1\"],\n",
    "    raw_datasets[\"train\"][\"sentence2\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509983f",
   "metadata": {},
   "source": [
    "è¿™ç§å¤„ç†æ–¹æ³•æ˜¯okçš„ï¼Œä½†ç¼ºç‚¹æ˜¯å¤„ç†ä¹‹åtokenized_datasetä¸å†æ˜¯ä¸€ä¸ªdatasetæ ¼å¼ï¼Œè€Œæ˜¯è¿”å›å­—å…¸ï¼ˆå¸¦æœ‰æˆ‘ä»¬çš„é”®:input_idsã€attention_mask å’Œ token_type_idsï¼Œå¯¹åº”çš„é”®å€¼å¯¹çš„å€¼ï¼‰ã€‚ è€Œä¸”ä¸€æ—¦æˆ‘ä»¬çš„datasetè¿‡å¤§ï¼Œæ— æ³•æ”¾åœ¨å†…å­˜ä¸­ï¼Œé‚£ä¹ˆè¿™æ ·å­çš„åšæ³•ä¼šå¯¼è‡´ Out of Memory çš„å¼‚å¸¸ã€‚ï¼ˆ ğŸ¤— Datasets åº“ä¸­çš„æ•°æ®é›†æ˜¯å­˜å‚¨åœ¨ç£ç›˜ä¸Šçš„ Apache Arrow æ–‡ä»¶ï¼Œå› æ­¤è¯·æ±‚åŠ è½½çš„æ ·æœ¬éƒ½ä¿å­˜åœ¨å†…å­˜ä¸­ï¼‰ã€‚\n",
    "\n",
    "ä¸ºäº†ä½¿æˆ‘ä»¬çš„æ•°æ®ä¿æŒdatasetçš„æ ¼å¼ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›´çµæ´»çš„Dataset.map æ–¹æ³•ã€‚æ­¤æ–¹æ³•å¯ä»¥å®Œæˆæ›´å¤šçš„é¢„å¤„ç†è€Œä¸ä»…ä»…æ˜¯ tokenizationã€‚ map æ–¹æ³•æ˜¯å¯¹æ•°æ®é›†ä¸­çš„æ¯ä¸ªå…ƒç´ åº”ç”¨åŒä¸€ä¸ªå‡½æ•°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥å¯¹è¾“å…¥è¿›è¡Œtokenizeé¢„å¤„ç†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793dceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5314a7a",
   "metadata": {},
   "source": [
    "è¿™ä¸ªå‡½æ•°æ¥å—çš„æ˜¯ä¸€ä¸ªå­—å…¸ï¼ˆå°±åƒæˆ‘ä»¬datasetçš„itemsï¼‰ï¼Œè¿”å›çš„ä¹Ÿæ˜¯ä¸€ä¸ªå­—å…¸ï¼ˆæœ‰ä¸‰ä¸ªé”®ï¼šinput_idsã€attention_mask å’Œ token_type_ids ï¼‰ã€‚ \n",
    "\n",
    "åœ¨tokenizationå‡½æ•°ä¸­çœç•¥äº†padding å‚æ•°ï¼Œè¿™æ˜¯å› ä¸ºpaddingåˆ°è¯¥æ‰¹æ¬¡ä¸­çš„æœ€å¤§é•¿åº¦æ—¶çš„æ•ˆç‡ï¼Œä¼šé«˜äºæ‰€æœ‰åºåˆ—éƒ½paddingåˆ°æ•´ä¸ªæ•°æ®é›†çš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚ å½“è¾“å…¥åºåˆ—é•¿åº¦å¾ˆä¸ä¸€è‡´æ—¶ï¼Œè¿™å¯ä»¥èŠ‚çœå¤§é‡æ—¶é—´å’Œå¤„ç†èƒ½åŠ›ï¼\n",
    "\n",
    "ä»¥ä¸‹æ˜¯å¯¹æ•´ä¸ªæ•°æ®é›†åº”ç”¨tokenizationæ–¹æ³•ã€‚ æˆ‘ä»¬åœ¨ map è°ƒç”¨ä¸­ä½¿ç”¨äº† batched=Trueï¼Œå› æ­¤è¯¥å‡½æ•°ä¸€æ¬¡åº”ç”¨äºæ•°æ®é›†çš„æ•´ä¸ªbatchå…ƒç´ ï¼Œè€Œä¸æ˜¯åˆ†åˆ«åº”ç”¨äºæ¯ä¸ªå…ƒç´ ã€‚ è¿™æ ·é¢„å¤„ç†é€Ÿåº¦ä¼šæ›´å¿«ï¼ˆå› ä¸º ğŸ¤— Tokenizers åº“ä¸­çš„Tokenizerç”¨ Rust ç¼–å†™ï¼Œä¸€æ¬¡å¤„ç†å¾ˆå¤šè¾“å…¥æ—¶è¿™ä¸ªåˆ†è¯å™¨å¯ä»¥éå¸¸å¿«ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11da7eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d311a1e6536742e69b412b1acaaf8864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d3b14eb47845828e1acdcc1a54f8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9222dc46474a0ea98231ee3cbeda9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d3d92",
   "metadata": {},
   "source": [
    ">å¦‚æœæ‚¨æ²¡æœ‰ä½¿ç”¨ç”±è¯¥åº“æ”¯æŒçš„fast tokenizerï¼ŒDataset.mapå‡½æ•°è¿›è¡Œé¢„å¤„ç†æ—¶å¯ä»¥è®¾å®šnum_proc å‚æ•°æ¥è¿›è¡Œå¤šçº¿ç¨‹å¤„ç†ï¼ŒåŠ å¿«é¢„å¤„ç†é€Ÿåº¦ã€‚\n",
    "\n",
    "æœ€åï¼Œå½“æˆ‘ä»¬å°†è¾“å…¥åºåˆ—è¿›è¡Œæ‰¹å¤„ç†æ—¶ï¼Œè¦å°†æ‰€æœ‰è¾“å…¥åºåˆ—å¡«å……åˆ°æœ¬æ‰¹æ¬¡æœ€é•¿åºåˆ—çš„é•¿åº¦â€”â€”æˆ‘ä»¬ç§°ä¹‹ä¸ºåŠ¨æ€å¡«å……æŠ€æœ¯dynamic padding(åŠ¨æ€å¡«å……ï¼šå³å°†æ¯ä¸ªæ‰¹æ¬¡çš„è¾“å…¥åºåˆ—å¡«å……åˆ°ä¸€æ ·çš„é•¿åº¦ã€‚å…·ä½“å†…å®¹æ”¾åœ¨æœ€åï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a5a4c",
   "metadata": {},
   "source": [
    "###  ä½¿ç”¨ Trainer API åœ¨ PyTorch ä¸­è¿›è¡Œå¾®è°ƒ\n",
    "ç”±äº PyTorch ä¸æä¾›å°è£…å¥½çš„è®­ç»ƒå¾ªç¯ï¼ŒğŸ¤— Transformers åº“å†™äº†äº†ä¸€ä¸ªtransformers.Trainer APIï¼Œå®ƒæ˜¯ä¸€ä¸ªç®€å•ä½†åŠŸèƒ½å®Œæ•´çš„ PyTorch è®­ç»ƒå’Œè¯„ä¼°å¾ªç¯ï¼Œé’ˆå¯¹ ğŸ¤— Transformers è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæœ‰å¾ˆå¤šçš„è®­ç»ƒé€‰é¡¹å’Œå†…ç½®åŠŸèƒ½ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå¤šGPU/TPUåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ã€‚å³Trainer APIæ˜¯ä¸€ä¸ªå°è£…å¥½çš„è®­ç»ƒå™¨ï¼ˆTransformersåº“å†…ç½®çš„å°æ¡†æ¶ï¼Œå¦‚æœæ˜¯Tensorflowï¼Œåˆ™æ˜¯TFTrainerï¼‰ã€‚\n",
    "\n",
    "æ•°æ®é¢„å¤„ç†å®Œæˆåï¼Œåªéœ€è¦å‡ ä¸ªç®€å•çš„æ­¥éª¤æ¥å®šä¹‰Trainerçš„å‚æ•°ï¼Œå°±å¯ä»¥ä½¿ç”¨ Trainer è¿›è¡Œæ¨¡å‹çš„åŸºæœ¬è®­ç»ƒå¾ªç¯äº†ï¼ˆå¦åˆ™çš„è¯ï¼Œè¦è‡ªå·±ä»å¤´åŠ è½½å’Œé¢„å¤„ç†æ•°æ®ï¼Œè®¾ç½®å„ç§å‚æ•°ï¼Œä¸€æ­¥æ­¥ç¼–å†™è®­ç»ƒå¾ªç¯ã€‚è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯çš„å†…å®¹åœ¨æœ¬èŠ‚æœ€åï¼‰ã€‚ \n",
    "\n",
    "Traineræœ€å›°éš¾çš„éƒ¨åˆ†å¯èƒ½æ˜¯å‡†å¤‡è¿è¡Œ Trainer.train çš„ç¯å¢ƒï¼Œå› ä¸ºå®ƒåœ¨ CPU ä¸Šè¿è¡Œé€Ÿåº¦éå¸¸æ…¢ã€‚ï¼ˆ å¦‚æœæ‚¨æ²¡æœ‰è®¾ç½® GPUï¼Œåˆ™å¯ä»¥åœ¨ Google Colab ä¸Šè®¿é—®å…è´¹çš„ GPU æˆ– TPUï¼‰\n",
    "\n",
    "trainerä¸»è¦å‚æ•°åŒ…æ‹¬ï¼š\n",
    "- Modelï¼šç”¨äºè®­ç»ƒã€è¯„ä¼°æˆ–ç”¨äºé¢„æµ‹çš„æ¨¡å‹\n",
    "- args (TrainingArgumentsï¼‰ï¼šè®­ç»ƒè°ƒæ•´çš„å‚æ•°ã€‚å¦‚æœæœªæä¾›ï¼Œå°†é»˜è®¤ä¸º TrainingArguments çš„åŸºæœ¬å®ä¾‹\n",
    "- data_collatorï¼ˆDataCollatorï¼Œå¯é€‰ï¼‰â€“ ç”¨äºæ‰¹å¤„ç†train_dataset æˆ– eval_dataset çš„çš„å‡½æ•°\n",
    "- train_datasetï¼šè®­ç»ƒé›†\n",
    "- eval_datasetï¼šéªŒè¯é›†\n",
    "- compute_metricsï¼šç”¨äºè®¡ç®—è¯„ä¼°æŒ‡æ ‡çš„å‡½æ•°ã€‚å¿…é¡»ä¼ å…¥EvalPrediction å¹¶å°†è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œé”®å€¼å¯¹æ˜¯metricå’Œå…¶valueã€‚\n",
    "- callbacks ï¼ˆå›è°ƒå‡½æ•°ï¼Œå¯é€‰ï¼‰ï¼šç”¨äºè‡ªå®šä¹‰è®­ç»ƒå¾ªç¯çš„å›è°ƒåˆ—è¡¨ï¼ˆList of TrainerCallbackï¼‰\n",
    "- optimizersï¼šä¸€ä¸ªåŒ…å«ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒæ•´å™¨çš„å…ƒç»„ï¼Œé»˜è®¤ä¼˜åŒ–å™¨æ˜¯AdamWï¼Œé»˜è®¤çš„å­¦ä¹ ç‡æ˜¯çº¿æ€§çš„å­¦ä¹ ç‡ï¼Œä»5e-5 åˆ° 0\n",
    "\n",
    "\n",
    "é™¤äº†ä»¥ä¸Šä¸»è¦å‚æ•°è¿˜æœ‰ä¸€äº›å‚æ•°å’Œå±æ€§ï¼ˆå¾—æœ‰å‡ åä¸ªå§ï¼Œå¯ä»¥æ…¢æ…¢çœ‹ã€‚å®Œæ•´çš„Traineræ–‡æ¡£å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainer#transformers.Trainer)ï¼‰\n",
    "\n",
    "ä¸‹é¢çš„ä»£ç ç¤ºä¾‹å‡å®šæ‚¨å·²ç»æ‰§è¡Œäº†ä¸Šä¸€èŠ‚ä¸­çš„ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f3b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\Administrator\\.cache\\huggingface\\datasets\\glue\\mrpc\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db34e0abde95433f9c991d93b97ae0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca002bb474f642d4bd44446f57256732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71ee820d7a745be9768507ce64dfb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")#MRPCåˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦äº’ä¸ºparaphrases\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)#åŠ¨æ€å¡«å……ï¼Œå³å°†æ¯ä¸ªæ‰¹æ¬¡çš„è¾“å…¥åºåˆ—å¡«å……åˆ°ä¸€æ ·çš„é•¿åº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f470a3",
   "metadata": {},
   "source": [
    "#### è®­ç»ƒ\n",
    "Trainer ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯TrainingArgumentsç±»ï¼Œæ˜¯ä¸€ä¸ªä¸è®­ç»ƒå¾ªç¯æœ¬èº«ç›¸å…³çš„å‚æ•°çš„å­é›†ï¼ŒåŒ…å« Trainerä¸­ç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„æ‰€æœ‰è¶…å‚æ•°ã€‚ å”¯ä¸€ä¸€ä¸ªå¿…é¡»æä¾›çš„å‚æ•°æ˜¯ï¼šä¿å­˜modelæˆ–è€…è¯´æ˜¯checkpointçš„ç›®å½•ï¼Œå…¶å®ƒå‚æ•°å¯ä»¥é€‰å–é»˜è®¤å€¼ï¼ˆæ¯”å¦‚é»˜è®¤è®­ç»ƒ3ä¸ªepochç­‰ï¼‰ï¼ˆTrainingArgumentsä¹Ÿæœ‰å‡ åä¸ªå‚æ•°ï¼Œï¼Œå¸¸è§å‚æ•°å†™åœ¨æ–‡æœ«ï¼Œå®Œæ•´æ–‡æ¡£åŒ…å«åœ¨ä¸Šé¢è¯´çš„Traineræ–‡æ¡£é‡Œï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83b72087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffa1e7",
   "metadata": {},
   "source": [
    "ç¬¬äºŒæ­¥ï¼šå®šä¹‰æ¨¡å‹\n",
    "å’Œä¸Šä¸€èŠ‚ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ AutoModelForSequenceClassification ç±»ï¼Œå¸¦æœ‰ä¸¤ä¸ªæ ‡ç­¾ï¼š\n",
    "ï¼ˆ***å…¶å®å°±æ˜¯æ ¹æ®è‡ªå·±çš„ä»»åŠ¡é€‰æ‹©ä»»åŠ¡å¤´task headï¼Œä»¥ä¾¿è¿›è¡Œå¾®è°ƒ***ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "222e5932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)#æ ‡ç­¾æ•°ä¸º2ä¹Ÿå°±æ˜¯äºŒåˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cedda",
   "metadata": {},
   "source": [
    "åœ¨å®ä¾‹åŒ–æ­¤é¢„è®­ç»ƒæ¨¡å‹åä¼šæŠ¥ä¸€ä¸ªwarningã€‚ è¿™æ˜¯å› ä¸º BERT æ²¡æœ‰åœ¨å¥å­å¯¹åˆ†ç±»æ–¹é¢è¿›è¡Œè¿‡é¢„è®­ç»ƒï¼Œæ‰€ä»¥é¢„è®­ç»ƒæ¨¡å‹çš„headå·²ç»è¢«ä¸¢å¼ƒï¼Œè€Œæ˜¯æ·»åŠ äº†ä¸€ä¸ªé€‚åˆåºåˆ—åˆ†ç±»çš„new headã€‚ è­¦å‘Šè¡¨æ˜ä¸€äº›æƒé‡æ²¡æœ‰ä½¿ç”¨ï¼ˆå¯¹åº”äºä¸¢å¼ƒçš„é¢„è®­ç»ƒheadéƒ¨åˆ†ï¼‰ï¼Œè€Œå…¶ä»–ä¸€äº›æƒé‡è¢«éšæœºåˆå§‹åŒ–ï¼ˆnew headéƒ¨åˆ†ï¼‰ï¼Œ æœ€åé¼“åŠ±æ‚¨è®­ç»ƒæ¨¡å‹ã€‚\n",
    "\n",
    "æœ‰äº†æ¨¡å‹ä¹‹åï¼Œå°±å¯ä»¥å®šä¹‰ä¸€ä¸ªè®­ç»ƒå™¨Trainerï¼Œå°†è¿„ä»Šä¸ºæ­¢æ„å»ºçš„æ‰€æœ‰å¯¹è±¡ä¼ é€’ç»™å®ƒè¿›è¡Œæ¨¡å‹ç²¾è°ƒã€‚è¿™äº›å¯¹è±¡åŒ…æ‹¬ï¼šmodelã€training_argsã€è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€data_collator å’Œtokenizerã€‚ï¼ˆè¿™éƒ½æ˜¯Trainerçš„å‚æ•°ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9a03100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8246ae",
   "metadata": {},
   "source": [
    "åƒä¸Šé¢è¿™æ ·ä¼ é€’tokenizeræ—¶ï¼Œå‚æ•°data_collator æ˜¯ä¹‹å‰å®šä¹‰çš„åŠ¨æ€å¡«å……DataCollatorWithPaddingï¼Œæ‰€ä»¥æ­¤è°ƒç”¨ä¸­çš„ data_collator=data_collatorè¡Œå¯ä»¥è·³è¿‡ã€‚ï¼ˆä½†æ˜¯åƒä¹‹å‰ä¸€æ ·å†™å‡ºè¿™ä¸€æ­¥å¾ˆé‡è¦It was still important to show you this part of the processing in section 2!ï¼‰\n",
    "\n",
    "è¦åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€è¦è°ƒç”¨ Trainer çš„ trainæ–¹æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cc93ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 3.30 MiB free; 1.21 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_520/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp_with_transformers\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1095\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp_with_transformers\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp_with_transformers\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlp_with_transformers\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                     \u001b[1;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg_sq\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_avg_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg_sq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 3.30 MiB free; 1.21 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d818d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_with_transformers]",
   "language": "python",
   "name": "conda-env-nlp_with_transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
